name: DSE Market Depth Scraper

on:
  schedule:
    # Run at 8:00 UTC (2:00 PM Bangladesh time)
    - cron: '0 8 * * 1-5'
    # Run every 10 minutes from 8:10 to 10:50 UTC (2:10 PM to 4:50 PM Bangladesh time)
    - cron: '10,20,30,40,50 8-10 * * 1-5'
  workflow_dispatch:  # Allow manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Set up Chrome and ChromeDriver
        run: |
          # Install Chrome if needed
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
    
    - name: Install Chrome and dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wget unzip xvfb libxi6 libgconf-2-4
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo apt install -y ./google-chrome-stable_current_amd64.deb
      
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create token file
      run: |
        echo "${{ secrets.CREDENTIALS_JSON }}" > credentials.json
        
    - name: Run scraper
      env:
        DRIVE_FOLDER_ID: ${{ secrets.DRIVE_FOLDER_ID }}
      run: python main.py
